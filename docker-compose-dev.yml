version: "3.3"
services:
  
  # Message queue required by Celery for distributed messaging between the workers
  rabbitmq:
     image: rabbitmq:3.8
     restart: always
     environment:
       RABBITMQ_DEFAULT_USER:
       RABBITMQ_DEFAULT_PASS:
       RABBITMQ_PORT: 5672
     expose:
       - 5672

  # Graph database used for discovery
  neo4j:
    image: neo4j:5.3.0
    expose:
      - 7474
      - 7687
    volumes:
      - neo4jdata:/data
    environment:
      NEO4J_AUTH:
      NEO4J_dbms_security_auth__minimum__password__length: 3

  # API for public access
  api:
    build: ./backend
    ports:
      - "8080:8080"
    depends_on:
      - neo4j
    volumes:
      - ./backend:/backend
      - ./backend/logs:/logs
      - ./data:/data
    command:  sh -c "./wait && watchmedo auto-restart --debug-force-polling -d /backend/app.py -- ./start.sh"
    restart: always
    tty: true
    privileged: true
    environment: &backend_env
      WAIT_HOSTS: neo4j:7474, neo4j:7687
      PYTHONUNBUFFERED: 1
      FLASK_ENV: development
      DAISY_PRODUCTION: false
      DATA_INGESTION_INTERVAL:
      DATA_ROOT_PATH: /data
      VALENTINE_THRESHOLD:
      VALENTINE_ROWS_TO_USE:
      REDIS_HOST:
      REDIS_PORT:
      REDIS_PASSWORD:
      RABBITMQ_HOST:
      RABBITMQ_PORT:
      RABBITMQ_DEFAULT_USER:
      RABBITMQ_DEFAULT_PASS:
      RABBITMQ_VHOST:
      NEO4J_AUTH:
      NEO4J_ADDRESS:

  # Celery worker that does schema matching jobs
  celery-worker:
    build: ./backend
    volumes:
      - ./backend:/backend
      - ./data:/data
    restart: always
    environment: *backend_env
    # Polling is required because inotify does not work on subfolders of bind mounts
    command: watchmedo auto-restart --debug-force-polling -d /backend/utility/celery_tasks.py -d /backend/__init__.py -- celery -A backend.celery worker -l INFO --concurrency=1
    depends_on:
      - rabbitmq
      - redis
      - neo4j

  # Celery beat, used for  scheduling
  celery-beat:
    build: ./backend
    volumes:
      - celerydata:/celerydata
    restart: always
    environment: *backend_env
    # Polling is required because inotify does not work on subfolders of bind mounts
    command: watchmedo auto-restart --debug-force-polling -d /backend/utility/celery_tasks.py -d /backend/__init__.py -- celery -A backend.celery beat -l INFO
    depends_on:
      - rabbitmq

  # Dashboard for Celery
  celery-flower:
    build: ./backend
    volumes:
      - ./backend:/backend
    command: "celery -A backend.celery flower --broker_api=http://rabbitmq:rabbitmq@rabbitmq:15672/api/"
    restart: always
    environment: *backend_env
    expose:
      - 5555
    depends_on:
      - rabbitmq
      - celery-worker

  # In-memory store with persistence used for storing daisy table metadata and celery task information/statuses
  redis:
    image: redis/redis-stack:latest
    environment:
      REDIS_ARGS: --maxmemory 512mb --requirepass redis
    expose:
      - 6379
    volumes:
      - redisdata:/data

volumes:
  redisdata:
  neo4jdata:
  celerydata:
  data: