version: "3.3"
services:
  
  # Message queue required by Celery for distributed messaging between the workers
  rabbitmq:
     image: rabbitmq:3.8-management
     restart: always
     env_file:
       - .env
     ports:
       - "5672:5672"
       - "15672:15672"

  # Graph database used for discovery
  neo4j:
    image: neo4j
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4jdata:/data
    env_file:
      - .env

  # API for public access
  api:
    build: ./backend
    ports:
      - "443:443"
    depends_on:
      - neo4j
    volumes:
      - ./backend:/backend
      - ./backend/logs:/logs
      - ./data:/data

    command:  sh -c "./wait && watchmedo auto-restart --debug-force-polling -d /backend/app.py -- ./start.sh"
    restart: always
    tty: true
    privileged: true
    environment:
      WAIT_HOSTS: neo4j:7474, neo4j:7687
      PYTHONUNBUFFERED: 1
      FLASK_ENV: development
    env_file:
      - .env

  # Celery worker that does schema matching jobs
  celery-worker:
    build: ./backend
    volumes:
      - ./backend:/backend
      - ./data:/data
    restart: always
    environment:
      PYTHONUNBUFFERED: 1
    env_file:
      - .env
    # Polling is required because inotify does not work on subfolders of bind mounts
    command: watchmedo auto-restart --debug-force-polling -d /backend/utility/celery_tasks.py -d /backend/__init__.py -- celery -A backend.celery worker -l INFO --concurrency=1
    depends_on:
      - rabbitmq

  # Celery beat, used for  scheduling
  celery-beat:
    build: ./backend
    volumes:
      - ./backend:/backend
      - ./data:/data
    restart: always
    environment:
      PYTHONUNBUFFERED: 1
    env_file:
      - .env
    # Polling is required because inotify does not work on subfolders of bind mounts
    command: watchmedo auto-restart --debug-force-polling -d /backend/utility/celery_tasks.py -d /backend/__init__.py -- celery -A backend.celery beat -l INFO
    depends_on:
      - rabbitmq

  # Dashboard for Celery
  celery-flower:
    build: ./backend
    volumes:
      - ./backend:/backend
    command: "celery -A backend.celery flower --broker_api=http://rabbitmq:rabbitmq@rabbitmq:15672/api/"
    restart: always
    environment:
      FLOWER_PORT: 5555
    env_file:
      - .env
    ports:
      - "5555:5555"
    depends_on:
      - rabbitmq
      - celery-worker

  # In-memory store with persistence used for storing daisy table metadata and celery task information/statuses
  redis:
    image: redis/redis-stack:latest
    environment:
      REDIS_ARGS: --maxmemory 512mb --requirepass redis
    env_file:
      - .env
    ports:
      - "6379:6379"
      - "8001:8001"    
    volumes:
      - redisdata:/data

volumes:
  redisdata:
  neo4jdata:
